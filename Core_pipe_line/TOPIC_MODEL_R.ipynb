{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data from corpus and building the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panda and sqlite import\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# data base path\n",
    "db_path = 'C:/Users/8897p/OneDrive/Desktop/NLP/Project/AXR/processed_articles.db'\n",
    "\n",
    "# open the connection to the data base\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# create the pandas data frame with full table data\n",
    "query = \"SELECT * FROM articles\"\n",
    "df_corpus = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the connection after loading the data\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom method to extract the word frequency vectors from highlights text.\n",
    "\n",
    "Tunning done on how often the word occurs and how least it occurs, eliminating the outliers from the topic modeling consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# custom function to process the text and vectorize \n",
    "def preprocess_text(text_corpus):\n",
    "    # Addition words to ignore\n",
    "    custom_stop_words = ['day', 'say', 'says', 'time', 'got', 'new', 'week','said']  # Replace with the words you want to remove\n",
    "\n",
    "    # Combining them with default English stop words\n",
    "    combined_stop_words = set(custom_stop_words).union(set(CountVectorizer(stop_words='english').get_stop_words()))\n",
    "\n",
    "    # Create the vercorizer\n",
    "    vectorizer = CountVectorizer(max_df=0.91, min_df=2, stop_words=list(combined_stop_words)) # parameter tunning of max and minimum frequencies\n",
    "    dt_matrix = vectorizer.fit_transform(text_corpus)\n",
    "    return dt_matrix, vectorizer\n",
    "\n",
    "# generating the document frequncy model and getting the learned vectorizer on vocabulary\n",
    "dt_matrix, vectorizer = preprocess_text(df_corpus['highlights'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the word vectors to implement the LDA algorithm to find the best words to model the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Creating the LDA object\n",
    "num_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=123) # number of topics and random state set for easy tunning, same results on different parameters\n",
    "\n",
    "# Fit the LDA model to the document-term matrix and retrieve the topic distribution\n",
    "lda.fit(dt_matrix)\n",
    "lda_topic_dist = lda.transform(dt_matrix)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating throught the topics and displaying them. Sorted in as low to high value. Top 5 are the last 5 topic word distribution rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  ['include', 'told', 'police', 'suicide', 'house', 'iraq', 'people', 'syria', 'president', 'mama']\n",
      "Topic 2:  ['hits', 'history', 'world', 'official', 'america', 'united', 'children', 'died', 'police', 'people']\n",
      "Topic 3:  ['christian', 'world', 'women', 'names', 'just', 'inland', 'baby', 'long', 'australia', 'year']\n",
      "Topic 4:  ['president', 'fans', 'couple', 'rock', 'games', 'reported', 'shake', 'seen', 'white', 'young']\n",
      "Topic 5:  ['players', 'today', 'mama', 'china', 'law', 'left', 'president', 'security', 'america', 'people']\n"
     ]
    }
   ],
   "source": [
    "# Custom function to display topics and their top words\n",
    "def display_topics(model, feature_names, num_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx + 1}: \", [feature_names[i] for i in topic.argsort()[-num_top_words:]])\n",
    "\n",
    "# Display topics\n",
    "display_topics(lda, vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning topic numbers and custom labels for furthur processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highlights</th>\n",
       "      <th>assigned_topic</th>\n",
       "      <th>topic_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan's chief cabinet secretary Yoshihide suga...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sports and Geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syria official mama climbed to the top of the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Middle East and Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The employee in agency canvas City office is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Middle East and Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW A canada doctor says she was part of a tea...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sports and Geopolitics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW 4 groups announce legal challenge in Phoen...</td>\n",
       "      <td>4</td>\n",
       "      <td>Sports and Geopolitics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          highlights  assigned_topic  \\\n",
       "0  japan's chief cabinet secretary Yoshihide suga...               4   \n",
       "1  syria official mama climbed to the top of the ...               0   \n",
       "2  The employee in agency canvas City office is a...               0   \n",
       "3  NEW A canada doctor says she was part of a tea...               4   \n",
       "4  NEW 4 groups announce legal challenge in Phoen...               4   \n",
       "\n",
       "                topic_label  \n",
       "0    Sports and Geopolitics  \n",
       "1  Middle East and Politics  \n",
       "2  Middle East and Politics  \n",
       "3    Sports and Geopolitics  \n",
       "4    Sports and Geopolitics  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning a topic out of the 5 modeled\n",
    "df_corpus['assigned_topic'] = lda_topic_dist.argmax(axis=1)\n",
    "\n",
    "# Custom labels for the topic document probabilities\n",
    "topic_labels = {\n",
    "    0: \"Middle East and Politics\",\n",
    "    1: \"Historical Events and Police Reports\",\n",
    "    2: \"Christianity and Culture\",\n",
    "    3: \"Entertainment and Youth\",\n",
    "    4: \"Sports and Geopolitics\",\n",
    "}\n",
    "\n",
    "# Map for the numeric to text form of topics\n",
    "df_corpus['topic_label'] = df_corpus['assigned_topic'].map(topic_labels)\n",
    "\n",
    "# Sample head display\n",
    "df_corpus[['highlights', 'assigned_topic', 'topic_label']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          highlights  assigned_topic  \\\n",
      "0  japan's chief cabinet secretary Yoshihide suga...               4   \n",
      "1  syria official mama climbed to the top of the ...               0   \n",
      "2  The employee in agency canvas City office is a...               0   \n",
      "3  NEW A canada doctor says she was part of a tea...               4   \n",
      "4  NEW 4 groups announce legal challenge in Phoen...               4   \n",
      "\n",
      "                topic_label  \n",
      "0    Sports and Geopolitics  \n",
      "1  Middle East and Politics  \n",
      "2  Middle East and Politics  \n",
      "3    Sports and Geopolitics  \n",
      "4    Sports and Geopolitics  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# create the new Database with topics\n",
    "conn = sqlite3.connect('Modeler_output_topics.db')\n",
    "\n",
    "# Data frame to data base convertion\n",
    "df_corpus.to_sql('topic_data', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Validation of the data inserted\n",
    "query = \"SELECT highlights, assigned_topic, topic_label FROM topic_data LIMIT 5;\"\n",
    "df_verification = pd.read_sql(query, conn)\n",
    "print(df_verification)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeler evalution and possible hybrid approach application"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
